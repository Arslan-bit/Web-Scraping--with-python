{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from  bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import string\n",
    "from urllib.request import Request, urlopen\n",
    "import re\n",
    "import os\n",
    "from urllib.parse import urljoin\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ronanherry.org/\n"
     ]
    }
   ],
   "source": [
    "# url = 'https://techfor.netlify.app'\n",
    "# url = 'https://alltop.netlify.app'\n",
    "# url ='https://patato.co/en'\n",
    "url = 'https://ronanherry.org/'\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get The Heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_H = url\n",
    "r = requests.get(url_H)\n",
    "htmlcontents  = r.content\n",
    "# print(htmlcontents)\n",
    "soop = BeautifulSoup(htmlcontents,'html.parser')\n",
    "# print(soop.prettify())\n",
    "\n",
    "paragraph = soop.find_all('p')\n",
    "# print(paragraph)\n",
    "\n",
    "heading = soop.find('title')\n",
    "heaad = heading.text\n",
    "\n",
    "# heaad = heaad.split(' ')[:3] if len(heaad.split(' ')) > 1 else heaad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ronan Herry\n"
     ]
    }
   ],
   "source": [
    "print((heaad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse the Heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ronan Herry\n"
     ]
    }
   ],
   "source": [
    "# a_string = '!hi. wh?at is the weat[h]er lik?e.'\n",
    "a_string = heaad\n",
    "new_string = a_string.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "print(new_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Main Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'Ronan Herry' created\n",
      "C:/Scraping/Ronan Herry\n"
     ]
    }
   ],
   "source": [
    "# Directory\n",
    "directory = new_string\n",
    "  \n",
    "# Parent Directory path\n",
    "parent_dir = \"C:/Scraping/\"\n",
    "  \n",
    "# Path join\n",
    "path = os.path.join(parent_dir, directory)\n",
    "  \n",
    "os.mkdir(path)\n",
    "print(\"Directory '% s' created\" % directory)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make List Sub Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_add_dir = parent_dir + directory +\"/\"\n",
    "# print(sub_add_dir)\n",
    "list = [\"html\",\"css\",\"java\",\"Img\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Sub Directory in Main Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'html' created\n",
      "Directory 'css' created\n",
      "Directory 'java' created\n",
      "Directory 'Img' created\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "while n <len(list):\n",
    "    sub_directory =list[n] \n",
    "\n",
    "    # Path join\n",
    "    spath = os.path.join(sub_add_dir, sub_directory)\n",
    "\n",
    "    os.mkdir(spath)\n",
    "    \n",
    "    print(\"Directory '% s' created\" % sub_directory)\n",
    "    \n",
    "    n=n+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['css', 'html', 'Img', 'java']\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "N_folder = os.listdir(path)\n",
    "print(N_folder)\n",
    "n = len(N_folder)\n",
    "print(n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create .txt file in the sub Directorys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "C:/Scraping/Ronan Herry/css/css.txt\n",
      "html\n",
      "Img\n",
      "C:/Scraping/Ronan Herry/java/java.txt\n"
     ]
    }
   ],
   "source": [
    "print('ok')\n",
    "\n",
    "n=0\n",
    "while n<len(N_folder):\n",
    "    \n",
    "    if N_folder[n] == \"html\" :\n",
    "        print(N_folder[n])\n",
    "        \n",
    "    elif N_folder[n] == \"Img\" :\n",
    "        print(N_folder[n])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        file = open(path + '/' + N_folder[n] + '/' + N_folder[n] + '.txt','w')\n",
    "        file.close\n",
    "        print((path + '/' + N_folder[n] + '/' + N_folder[n] + '.txt'))\n",
    "    \n",
    "    n=n+1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract & split the HTML and save in html.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n",
      "<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
      "<title>Ronan Herry</title>\n",
      "<meta content=\"Ronan Herry homepage.\" name=\"description\"/>\n",
      "<link href=\"/\" rel=\"canonical\"/>\n",
      "<link href=\"/css/css.css\" rel=\"stylesheet\"/>\n",
      "<link href=\"\" rel=\"icon\" type=\"image/png\"/>\n",
      "<!--script type=\"text/javascript\"\n",
      "            src=\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\">\n",
      "    </script -->\n",
      "<!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->\n",
      "<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->\n",
      "<!--[if lt IE 9]>\n",
      "      <script src=\"assets/js/html5shiv.min.js\"></script>\n",
      "      <script src=\"assets/js/respond.min.js\"></script>\n",
      "    <![endif]-->\n",
      "</head>\n",
      "<body>\n",
      "<nav class=\"navbar\">\n",
      "<ul class=\"inline-block\">\n",
      "<li class=\"active\"><a href=\"/\">Home</a></li>\n",
      "<li><a href=\"/publications/\">Research papers</a></li>\n",
      "<li><a href=\"/talks/\">Scientific talks</a></li>\n",
      "<li><a href=\"/teaching/\">Teaching</a></li>\n",
      "</ul>\n",
      "</nav>\n",
      "<section class=\"main-content\">\n",
      "<header>\n",
      "<h1>Ronan Herry</h1>\n",
      "</header>\n",
      "<ul class=\"block-list\">\n",
      "<li>\n",
      "<article>\n",
      "<header>\n",
      "<h4>Position</h4>\n",
      "</header>\n",
      "<p>Since January, 2019, I am a wissenschaftlicher Mitarbeiter (research assistant) in <a href=\"http://wt.iam.uni-bonn.de/sturm/home/\">Karl-Theodor Sturm</a> group.\n",
      "<br/>\n",
      "In November 2015, I started to prepare a PhD in mathematics under the supervision of <a href=\"https://sites.google.com/view/nathaelgozlanmath/accueil\">Nathael Gozlan</a> and <a href=\"https://sites.google.com/site/giovannipeccati/Home\">Giovanni Peccati</a>.\n",
      "I defended my thesis on December 3, 2018.\n",
      "<br/>\n",
      "Before that, I was a research intern with <a href=\"http://djalil.chafai.net/\">Djalil Chafaï</a> in the framework of my master’s thesis.\n",
      "<br/></p>\n",
      "</article>\n",
      "</li>\n",
      "<li>\n",
      "<article>\n",
      "<header>\n",
      "<h4>Research topics</h4>\n",
      "</header>\n",
      "<p>I am working in the field of Stochastic analysis, Functional inequalities and Optimal transport.\n",
      "My main focus is the use of <em>optimal transport</em> and <em>functional inequalities</em> to study probabilistic models from statistical physics or mechanics, mostly <em>point processes</em> and <em>Liouville quantum gravity measures</em>.</p>\n",
      "<p>More specifically, I am interested in:</p>\n",
      "<ul>\n",
      "<li>Stochastic analysis and optimal transport for particle systems.</li>\n",
      "<li>Transport inequalities and concentration of measure.</li>\n",
      "<li>Functional inequalities for Markov semigroups à la Bakry-Emery.</li>\n",
      "<li>Heat kernels, Laplace operators and Ricci curvature on non-smooth spaces.</li>\n",
      "<li>Liouville quantum gravity measures in arbitrary dimension.</li>\n",
      "<li>Malliavin-Stein approach and limit theorems.</li>\n",
      "</ul>\n",
      "<p>More broadly, I am also interested with many aspects of modern probability such as free probability, rough paths, regularity structures, SPDEs, random geometry, percolation and their interplays with my field of expertise.</p>\n",
      "</article>\n",
      "</li>\n",
      "<li>\n",
      "<article>\n",
      "<header>\n",
      "<h4>Awards</h4>\n",
      "</header>\n",
      "<p>2018 Hannan Graduate Student Travel Award (<a href=\"http://bulletin.imstat.org/2018/05/2018-hannan-graduate-student-travel-awards/\">award announcement</a>).</p>\n",
      "</article>\n",
      "</li>\n",
      "<li>\n",
      "<article>\n",
      "<header>\n",
      "<h4>Service</h4>\n",
      "</header>\n",
      "<ul>\n",
      "<li>Since <time datetime=\"2020-03\">March 2020</time>, I co-organised with <a href=\"https://wt.iam.uni-bonn.de/ferrari/home\">Patrik Ferrari</a> and Francesco De Vecchi, the <a href=\"https://wt.iam.uni-bonn.de/event-calendar/events\">Oberseminar Stochastics</a> in Bonn.</li>\n",
      "<li>From <time datetime=\"2016-09\">September 2016</time> to <time datetime=\"2017-03\">March 2017</time>, together with my friend <a href=\"http://fpetit.org\">François Petit</a>, I co-organised the <a href=\"http://math.uni.lu/docsem\">PhD Seminar</a> of the mathematics department of the University of Luxembourg.</li>\n",
      "<li>In <time datetime=\"2016-06\">June 2016</time>, I animated a working group on functional inequalities and the KLS and Variance conjecture inside the Probability group.</li>\n",
      "<li>From <time datetime=\"2015-12\">December 2015</time> to <time datetime=\"2017-12\">December 2017</time>, I organised an <a href=\"seminar-probability\">internal seminar</a> in probability where people of the research group explain their current work.</li>\n",
      "</ul>\n",
      "</article>\n",
      "</li>\n",
      "</ul>\n",
      "</section>\n",
      "<aside class=\"contact\">\n",
      "<div>\n",
      "<address itemscope=\"\" itemtype=\"http://schema.org/Person\">\n",
      "<h1>Ronan Herry</h1>\n",
      "<h3>PhD</h3><br/>\n",
      "<p>\n",
      "      Institut für Angewandte Mathematik<br/>\n",
      "      Office: 4.039<br/>\n",
      "      Endenicher Allee 60<br/>\n",
      "      D-53115 Bonn<br/>\n",
      "      Germany<br/><br/>\n",
      "</p>\n",
      "<p><i class=\"fa fa-envelope fa-fw\"></i><a href=\"mailto:herry@iam.uni-bonn.de\"> herry@iam.uni-bonn.de</a></p>\n",
      "<p><i class=\"fab fa-linkedin fa-fw\"></i> <a href=\"https://linkedin.com/in/ronanherry/en\" target=\"_blank\">Ronan Herry</a></p>\n",
      "<p><i class=\"fas fa-file-alt fa-fw\"></i> <a href=\"/downloads/cv_R_Herry.pdf\" target=\"_blank\">CV (french)</a>\n",
      "</p></address>\n",
      "</div>\n",
      "</aside>\n",
      "<aside class=\"notice\">\n",
      "<p>\n",
      "        This site is built using <a href=\"http://jekyllrb.com/\">Jekyll</a> &amp; <a href=\"http://ethanschoonover.com/solarized\">Solarized</a>.\n",
      "        Last update: 11 May 2022.\n",
      "      </p>\n",
      "</aside>\n",
      "</body>\n",
      "<script src=\"/js/main.js\"></script>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HTML\n",
    "URL_html = url\n",
    "req = Request(URL_html)\n",
    "html_page = urlopen(req)\n",
    "\n",
    "soup = BeautifulSoup(html_page, \"html.parser\")\n",
    "\n",
    "\n",
    "html_text = soup\n",
    "\n",
    "Func = open(path + '/' + N_folder[1] + '/' + N_folder[1] + '.html',\"w\")\n",
    "\n",
    "Func.write(str(soup))\n",
    "\n",
    "Func.close()\n",
    "\n",
    "print(str(soup))\n",
    "\n",
    "# img = soup.find(\"img\")[\"src\"]\n",
    "# print(img)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Https links from Html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ronanherry.org/\n",
      "https://ronanherry.org/\n",
      "https://ronanherry.org/\n",
      "https://ronanherry.org/\n",
      "https://ronanherry.org/\n",
      "https://ronanherry.org/\n",
      "https://ronanherry.org/\n",
      "https://ronanherry.org/\n",
      "https://ronanherry.org/\n",
      "https://ronanherry.org/\n",
      "https://ronanherry.org/\n",
      "https://ronanherry.org/\n",
      "https://ronanherry.org/\n",
      "https://ronanherry.org/\n",
      "https://ronanherry.org/\n",
      "https://ronanherry.org/\n",
      "https://ronanherry.org/\n",
      "https://ronanherry.org/\n",
      "https://ronanherry.org/\n"
     ]
    }
   ],
   "source": [
    "url1 = url\n",
    "response = requests.get(url1)\n",
    "# parse html\n",
    "page = str(BeautifulSoup(response.content))\n",
    "\n",
    "\n",
    "def getURL(page):\n",
    "    \"\"\"\n",
    "    :param page: html of web page (here: Python home page) \n",
    "    :return: urls in that page \n",
    "    \"\"\"\n",
    "    start_link = page.find(\"a href\")\n",
    "    if start_link == -1:\n",
    "        return None, 0\n",
    "    start_quote = page.find('\"', start_link)\n",
    "    end_quote = page.find('\"', start_quote + 1)\n",
    "    url = page[start_quote + 1: end_quote]\n",
    "    return url1, end_quote\n",
    "\n",
    "while True:\n",
    "    url1, n = getURL(page)\n",
    "    page = page[n:]\n",
    "    if url1:\n",
    "        print(url1)\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the images without https from HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from BeautifulSoup import BeautifulSoup\n",
    "URL_img = url\n",
    "# print(URL_img)\n",
    "\n",
    "# import re\n",
    "html_page = urlopen(req)\n",
    "soup = BeautifulSoup(html_page)\n",
    "images = []\n",
    "for img in soup.find_all('img'):\n",
    "    src = img.get('src').replace('./', '/')\n",
    "    if not src.startswith('/'): src = f'/{src}'\n",
    "#     print(src, type(src))\n",
    "    if 'http' not in src: images.append(src)\n",
    "\n",
    "links = []\n",
    "for line in images:\n",
    "\n",
    "     links.append(URL_img + line)\n",
    "    \n",
    "# print(links)\n",
    "        \n",
    "m = 0\n",
    "while m < len(links):\n",
    "    print(links[m])\n",
    "    \n",
    "    f = (links[m].split('/'))\n",
    "#     print(f)\n",
    "    r = requests.get(links[m], allow_redirects=True)\n",
    "    open(path + '/' + N_folder[2] + '/' + str(f[2]) + str(m) + '.png', 'wb').write(r.content)\n",
    "    \n",
    "    print('File Save ' + path + '/' + N_folder[2] + '/' + f[2]+ str(m) + '.png' + '\\n' )    \n",
    "    m=m+1\n",
    "        \n",
    "        \n",
    "# for link in links: print(link)\n",
    "# print(path)\n",
    "# # print(N_folder[2] )\n",
    "# # style.css/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Extract the Java and save in java.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ronanherry.org/js/main.js\n",
      " https://techfor.netlify.app\n"
     ]
    }
   ],
   "source": [
    "# Java Urls\n",
    "script_files = []\n",
    "\n",
    "for script in soup.find_all(\"script\"):\n",
    "    if script.attrs.get(\"src\"):\n",
    "        # if the tag has the attribute 'src'\n",
    "        script_url = urljoin(url, script.attrs.get(\"src\"))\n",
    "        script_files.append(script_url)\n",
    "        \n",
    "        \n",
    "# change list to text   \n",
    "java_text = \"\"\n",
    "\n",
    "for line in script_files:\n",
    "\n",
    "      java_text += line + \"\\n https://techfor.netlify.app\"\n",
    "\n",
    "        \n",
    "        \n",
    "# Add java urls in File\n",
    "f = open(path + '/' + N_folder[3] + '/' + N_folder[3] + '.txt','w',encoding='utf-8')         # Creating html_text.txt File\n",
    "\n",
    "for line in java_text:\n",
    "\tf.write(line)\n",
    "\n",
    "f.close()\n",
    "# print(script_files[0])\n",
    "print(java_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = requests.get(url, allow_redirects=True)\n",
    "\n",
    "# open(path + '/' + N_folder[2] + '/' + URL[2] + '.java', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Java files & save in Java Directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Save ronanherry.orgjs0.java\n"
     ]
    }
   ],
   "source": [
    "aa = 0\n",
    "while aa < len(script_files):\n",
    "    \n",
    "    url = script_files[aa]\n",
    "    URL = url.split('/')\n",
    "\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    java_path = (URL[2] + URL[3]+ str(aa)) \n",
    "\n",
    "    open(path + '/' + N_folder[3] + '/' + java_path + '.java', 'wb').write(r.content)\n",
    "    \n",
    "    print('File Save '+ java_path + '.java' )\n",
    "    \n",
    "    aa = aa+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Extract the CSS and save in css.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ronanherry.org/\n",
      "https://ronanherry.org/css/css.css\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CSS Urls\n",
    "css_files = []\n",
    "\n",
    "for css in soup.find_all(\"link\"):\n",
    "    if css.attrs.get(\"href\"):\n",
    "        # if the link tag has the 'href' attribute\n",
    "        css_url = urljoin(url, css.attrs.get(\"href\"))\n",
    "        css_files.append(css_url)\n",
    "        \n",
    "# change list to text       \n",
    "css_text = \"\"\n",
    "\n",
    "for line in css_files:\n",
    "\n",
    "      css_text += line + \"\\n\"\n",
    "\n",
    "\n",
    "        \n",
    "# Add css urls in File\n",
    "f = open(path + '/' + N_folder[0] + '/' + N_folder[0] + '.txt','w')         # Creating html_text.txt File\n",
    "\n",
    "for line in css_text:\n",
    "\tf.write(line)\n",
    "\n",
    "f.close()\n",
    "# print(css_files)\n",
    "print(css_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading CSS files & Img  & save in Css Directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_string = css_files[3]\n",
    "# # a_string = a_strin.split('.')\n",
    "# print(a_string)\n",
    "# new_string = a_string.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# print(new_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ronanherry.org/\n",
      "File Save ronanherry.org0.css\n",
      "https://ronanherry.org/css/css.css\n",
      "File Save ronanherry.org1.css\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "while a < len(css_files):\n",
    "    \n",
    "    url_css = css_files[a]\n",
    "    print(url_css)\n",
    "    URL = url_css.split('/')\n",
    "    URL_I = url_css.split('.')\n",
    "#     print(URL_I)\n",
    "    \n",
    "    \n",
    "\n",
    "    r = requests.get(url_css, allow_redirects=True)\n",
    "    java_path = (URL[2] + str(a)) \n",
    "\n",
    "    \n",
    "    \n",
    "    if (URL.count(\"Img\") > 0 or URL_I.count(\"png\") > 0):\n",
    "        open(path + '/' + N_folder[2] + '/' + java_path + '.png', 'wb').write(r.content)\n",
    "        print('File Save '+ java_path + '.png' )\n",
    "        \n",
    "    else: \n",
    "        open(path + '/' + N_folder[0] + '/' + java_path + '.css', 'wb').write(r.content)\n",
    "        print('File Save '+ java_path + '.css' )\n",
    "    \n",
    "    a = a+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urlll = \"https://techfor.netlify.app/img/third%20slide%20picture.jpg\"\n",
    "# r = requests.get(urlll, allow_redirects=True)\n",
    "# open(path + '/'+ \"urlll\" + '.png', 'wb').write(r.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
